{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bienvenido a la notebook de implementación de ...\n",
    "\n",
    "## 28 EMOCIONES\n",
    "\n",
    "## joeddav/distilbert-base-uncased-go-emotions-student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = os.getcwd()\n",
    "\n",
    "file_extension = \".pickle\"\n",
    "upload_folder = os.path.join(workdir, \"output_transcripcion\", \"sentiment-analysis\")\n",
    "\n",
    "# bloques descargados\n",
    "bloques = os.listdir(upload_folder)\n",
    "\n",
    "debate_dict = {}\n",
    "for bloque in bloques:\n",
    "    debate_dict[bloque] = {}\n",
    "    upload_folder_bloque = os.path.join(upload_folder, bloque)\n",
    "    # # filter files by extension\n",
    "    files = os.listdir(upload_folder_bloque)\n",
    "    files = [f for f in files if f.endswith(file_extension)]\n",
    "\n",
    "    for file in files:\n",
    "        with open(os.path.join(upload_folder_bloque, file), 'rb') as f:\n",
    "            # file remove extension\n",
    "            file = file[:-len(file_extension)]\n",
    "            debate_dict[bloque][file] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [ORIGINAL] : este funciona como un clasificador de una sola etiqueta\n",
    "\n",
    "if False:\n",
    "\n",
    "    MODEL_NAME = \"joeddav/distilbert-base-uncased-go-emotions-student\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    try:\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        for ix in range(0, num_gpus):\n",
    "            # select the latest recognized gpu - the only one in this case\n",
    "            device_id = 'cuda:{}'.format(ix)\n",
    "            device = torch.device(device_id)\n",
    "            print(\"GPU disponible, otorgada mediante el id: {}\".format(device_id))\n",
    "    except:\n",
    "        print(\"Esto debería imprimirse si no existen GPUs disponibles\")\n",
    "    \n",
    "    \n",
    "    # create instances of tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "    \n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer(muestra, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    # predict\n",
    "    # Predice\n",
    "    with torch.no_grad():\n",
    "        tokens = {key: value.to(device) for key, value in tokens.items()}  # Mueve los tensores a la GPU (o CPU)\n",
    "        outputs = model(**tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible, otorgada mediante el id: cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"joeddav/distilbert-base-uncased-go-emotions-student\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "try:\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    for ix in range(0, num_gpus):\n",
    "        # select the latest recognized gpu - the only one in this case\n",
    "        device_id = 'cuda:{}'.format(ix)\n",
    "        device = torch.device(device_id)\n",
    "        print(\"GPU disponible, otorgada mediante el id: {}\".format(device_id))\n",
    "except:\n",
    "    print(\"Esto debería imprimirse si no existen GPUs disponibles\")\n",
    "\n",
    "\n",
    "# create instances of tokenizer and model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=device, top_k=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bloque_de_desarrollo_humano_vivienda_y_protección_del_ambiente', 'bloque_de_preguntas_cruzadas', 'bloque_de_seguridad', 'bloque_de_trabajo_y_producción', 'introduccion'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agustin\\Desktop\\RD\\Octubre\\MODELO-16-EMOTIONS\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bloque = 'bloque_de_trabajo_y_producción'\n",
    "\n",
    "prediccion_dict = {}\n",
    "for participacion in debate_dict[bloque].keys():\n",
    "    prediccion_dict[participacion] = []\n",
    "    corpus = debate_dict[bloque][participacion]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = pipeline(corpus)\n",
    "\n",
    "    for ix, output in enumerate(outputs):\n",
    "        prediccion_dict[participacion].append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schiaretti_1\n",
      "Schiaretti_2\n",
      "Schiaretti_3\n",
      "Schiaretti_4\n",
      "Schiaretti_5\n",
      "Schiaretti_6\n",
      "Schiaretti_7\n",
      "Schiaretti_8\n",
      "Schiaretti_9\n",
      "Schiaretti_10\n",
      "Schiaretti_11\n",
      "Schiaretti_12\n",
      "Massa_1\n",
      "Massa_2\n",
      "Massa_3\n",
      "Massa_4\n",
      "Massa_5\n",
      "Massa_6\n",
      "Massa_7\n",
      "Massa_8\n",
      "Massa_9\n",
      "Massa_10\n",
      "Massa_11\n",
      "Massa_12\n",
      "Massa_13\n",
      "Massa_14\n",
      "Bregman_1\n",
      "Bregman_2\n",
      "Bregman_3\n",
      "Bregman_4\n",
      "Bregman_5\n",
      "Bregman_6\n",
      "Milei_1\n",
      "Milei_2\n",
      "Milei_3\n",
      "Milei_4\n",
      "Milei_5\n",
      "Milei_6\n",
      "Milei_7\n",
      "Schiaretti_1\n",
      "Schiaretti_2\n",
      "Schiaretti_3\n",
      "Schiaretti_4\n",
      "Schiaretti_5\n",
      "Schiaretti_6\n",
      "Schiaretti_7\n",
      "Bullrich_1\n",
      "Bullrich_2\n",
      "Bullrich_3\n",
      "Bullrich_4\n",
      "Bullrich_5\n",
      "Bullrich_6\n",
      "Massa_1\n",
      "Massa_2\n",
      "Massa_3\n",
      "Milei_1\n",
      "Milei_2\n",
      "Milei_3\n",
      "Schiaretti_1\n",
      "Schiaretti_2\n",
      "Schiaretti_3\n",
      "Schiaretti_4\n",
      "Massa_1\n",
      "Massa_2\n",
      "Massa_3\n",
      "Massa_4\n",
      "Schiaretti_1\n",
      "Schiaretti_2\n",
      "Bregman_1\n",
      "Bregman_2\n",
      "Bregman_3\n",
      "Bregman_4\n",
      "Bregman_5\n",
      "Bregman_6\n",
      "Bregman_7\n",
      "Bregman_8\n",
      "Bregman_9\n",
      "Bregman_10\n",
      "Milei_1\n",
      "Milei_2\n",
      "Milei_3\n",
      "Milei_4\n",
      "Milei_5\n",
      "Milei_6\n",
      "Milei_7\n",
      "Milei_8\n",
      "Milei_9\n",
      "Milei_10\n",
      "Bregman_1\n",
      "Bregman_2\n",
      "Bregman_3\n",
      "Milei_1\n",
      "Milei_2\n",
      "Milei_3\n",
      "Milei_1\n",
      "Milei_2\n",
      "Milei_3\n",
      "Milei_4\n",
      "Milei_5\n",
      "Milei_6\n",
      "Milei_7\n",
      "Massa_1\n",
      "Massa_2\n",
      "Massa_3\n",
      "Massa_4\n",
      "Bullrich_1\n",
      "Bullrich_2\n",
      "Bullrich_3\n",
      "Bullrich_4\n",
      "Bullrich_5\n",
      "Bullrich_6\n",
      "Bullrich_7\n",
      "Bullrich_8\n",
      "Bullrich_9\n",
      "Bullrich_10\n",
      "Bullrich_11\n"
     ]
    }
   ],
   "source": [
    "## Creacion de un único DataFrame con todos los scores de cada línea de su discurso.\n",
    "from itertools import count\n",
    "\n",
    "predicciones_frame = {}\n",
    "for participante in prediccion_dict.keys():\n",
    "    N = count(1)\n",
    "    df_limpio = pd.DataFrame()\n",
    "    for participacion in prediccion_dict[participante]:\n",
    "        df_aux = pd.DataFrame(participacion).set_index(\"label\")\n",
    "        df_aux *= 100\n",
    "        df_aux[\"score\"] = df_aux[\"score\"].round(2)\n",
    "        participante_N = participante.split(\"_\")[1] + \"_\" + str(next(N))#.zfill(2)#TODO: eliminar de j.r.d\n",
    "        print(participante_N)\n",
    "        df_aux = df_aux.rename(columns={\"score\": participante_N})\n",
    "        df_limpio = pd.concat([df_limpio, df_aux], axis=1)\n",
    "    predicciones_frame[participante] = df_limpio\n",
    "        \n",
    "    \n",
    "## Ejemplo de como comparar los scores con una linea del discurso en particular\n",
    "# si analizamos Bullrich_8, vemos que el score da:\n",
    "#   - 7,7% aprobación\n",
    "#   - 3.5; 3.4, 3., 3.4 de amor, optimismo, admiracion, alegría, aproximadamente\n",
    "#   - luego analizamos la línea en particular y vemos que dice:\n",
    "#           \" Y Milei se ha asociado hace pocos días con ellos también \"\n",
    "# linea = 8\n",
    "# predicciones_frame[\"2_Bullrich_1\"]\n",
    "# pd.DataFrame(debate_dict[\"introduccion\"][\"2_Bullrich_1\"]).T.iloc[:,linea-1].values[0]# Transmite Alegría, Amor, 7,7% aprobación, etc...\n",
    "\n",
    "# fin de la demostración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar los dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.feed import crear_directorio\n",
    "for frame in predicciones_frame.keys():# estamos usando variables de otra celda - bloque\n",
    "    output_folder = os.path.join(workdir, \"output_model_emotions\", bloque)\n",
    "    crear_directorio(output_folder, verbose=False)\n",
    "    \n",
    "    participacion = pd.DataFrame(debate_dict[bloque][frame]).T\n",
    "    \n",
    "    frame_num = frame.split(\"_\")[0].zfill(2)\n",
    "    frame_name = frame_num + \"_\" + \"_\".join(frame.split(\"_\")[1:])##TODO: actualizar en j.r.d\n",
    "    \n",
    "    \n",
    "    participacion.to_csv(os.path.join(output_folder, frame_name + \"_humano.csv\"))\n",
    "    with open(os.path.join(output_folder, frame_name + \"_prediccion.pickle\"), 'wb') as f:\n",
    "        pickle.dump(predicciones_frame[frame], f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Argentina tiene todo, pero los argentinos n...</td>\n",
       "      <td>Hace 20 años que la mafia política y sindical ...</td>\n",
       "      <td>Un juicio laboral se lleva a puesta una pyme, ...</td>\n",
       "      <td>Un empleo solo se consigue en la informalidad</td>\n",
       "      <td>Por eso nosotros queremos sacarle la pata enci...</td>\n",
       "      <td>Y nosotros defendemos a los que trabajan, no a...</td>\n",
       "      <td>Ustedes defienden a los sindicalistas que está...</td>\n",
       "      <td>Nosotros vamos a bajar impuestos al trabajo</td>\n",
       "      <td>Nosotros queremos hacer una verdadera ley para...</td>\n",
       "      <td>Por otro lado, te lo digo clarito, las indemni...</td>\n",
       "      <td>Cambia la Argentina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  La Argentina tiene todo, pero los argentinos n...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  Hace 20 años que la mafia política y sindical ...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  Un juicio laboral se lleva a puesta una pyme, ...   \n",
       "\n",
       "                                              3   \\\n",
       "0  Un empleo solo se consigue en la informalidad   \n",
       "\n",
       "                                                  4   \\\n",
       "0  Por eso nosotros queremos sacarle la pata enci...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  Y nosotros defendemos a los que trabajan, no a...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  Ustedes defienden a los sindicalistas que está...   \n",
       "\n",
       "                                            7   \\\n",
       "0  Nosotros vamos a bajar impuestos al trabajo   \n",
       "\n",
       "                                                  8   \\\n",
       "0  Nosotros queremos hacer una verdadera ley para...   \n",
       "\n",
       "                                                  9                    10  \n",
       "0  Por otro lado, te lo digo clarito, las indemni...  Cambia la Argentina  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participacion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
